{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7852de44-c003-4e1c-ad57-1d7e24066ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faker in /opt/conda/lib/python3.11/site-packages (37.11.0)\n",
      "Requirement already satisfied: tzdata in /opt/conda/lib/python3.11/site-packages (from faker) (2023.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install faker\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4569cd8-1987-4dac-9bd4-d8d53da40b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, rand, when, row_number\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import *\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65edcdde-1e69-4393-b486-5b32fa8ae5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RazorpayDataModeling\").getOrCreate()\n",
    "\n",
    "fake = Faker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "167ba8b5-70dc-4d1a-a3dd-9bc07a8c86be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" raw_merchant_profiles \"\"\"\n",
    "# Define the number of rows (merchants)\n",
    "NUM_MERCHANTS = 100\n",
    "\n",
    "# Lists to hold our data\n",
    "merchant_ids = []\n",
    "merchant_names = []\n",
    "signup_dates = []\n",
    "statuses = []\n",
    "\n",
    "# Loop to generate data\n",
    "for i in range(1, NUM_MERCHANTS + 1):\n",
    "    # 1. Generate a unique, consistent Merchant ID (our Business Key)\n",
    "    merchant_ids.append(f'MERCH_{i:04d}')\n",
    "    \n",
    "    # 2. Use Faker to create a realistic business name\n",
    "    merchant_names.append(fake.company())\n",
    "    \n",
    "    # 3. Create a realistic signup date\n",
    "    signup_dates.append(fake.date_time_between(start_date='-2y', end_date=datetime.now()))\n",
    "    \n",
    "    # 4. Assign a status (mostly Active, some Suspended/Inactive)\n",
    "    status_choices = ['Active'] * 80 + ['Suspended'] * 15 + ['Inactive'] * 5\n",
    "    statuses.append(random.choice(status_choices))\n",
    "\n",
    "# Create the DataFrame\n",
    "df_merchants = pd.DataFrame({\n",
    "    'merchant_id': merchant_ids,\n",
    "    'merchant_name': merchant_names,\n",
    "    'signup_date': signup_dates,\n",
    "    'status': statuses,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9051a17c-d3b7-4f56-a76f-d5bc3fe1581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" raw_merchant_subscriptions \"\"\"\n",
    "# Assuming df_merchants from the previous step is available\n",
    "\n",
    "subscription_data = []\n",
    "subscription_id_counter = 1\n",
    "\n",
    "# Loop through each merchant to ensure every merchant has at least one plan\n",
    "for merchant_id in df_merchants['merchant_id']:\n",
    "    # Ensure every merchant has a starting plan\n",
    "    num_plans = random.randint(1, 3) # Merchants will have 1 to 3 plan changes\n",
    "    \n",
    "    # Set the initial plan date slightly after their signup date\n",
    "    signup_date = df_merchants[df_merchants['merchant_id'] == merchant_id]['signup_date'].iloc[0]\n",
    "    \n",
    "    # Generate the historical plan records for this merchant\n",
    "    current_start_date = signup_date\n",
    "    \n",
    "    for _ in range(num_plans):\n",
    "        # Define the pricing tier and associated fee percentage\n",
    "        tier_options = {'Starter': 2.9, 'Pro': 1.5, 'Enterprise': 1.0}\n",
    "        \n",
    "        # Pick a random tier\n",
    "        tier, fee = random.choice(list(tier_options.items()))\n",
    "        \n",
    "        # Determine the effective date of this plan\n",
    "        # We need to ensure the end date is later than the start date\n",
    "        start_date = current_start_date\n",
    "        \n",
    "        # Set the end date for the plan. Use a future date for the last plan, \n",
    "        # or a past date for an historical plan.\n",
    "        if _ == num_plans - 1:\n",
    "             # The current, active plan\n",
    "            end_date = None\n",
    "        else:\n",
    "             # A historical, expired plan\n",
    "            end_date = fake.date_between(start_date=start_date, end_date= datetime.now())\n",
    "\n",
    "        subscription_data.append({\n",
    "            'subscription_id': f'SUB_{subscription_id_counter:04d}',\n",
    "            'merchant_id': merchant_id,\n",
    "            'pricing_tier': tier,\n",
    "            'fee_percentage': fee,\n",
    "            'start_date': start_date,\n",
    "            'end_date': end_date\n",
    "        })\n",
    "        subscription_id_counter += 1\n",
    "        \n",
    "        # Prepare the start date for the next plan change (if any)\n",
    "        if end_date:\n",
    "             current_start_date = pd.to_datetime(end_date) + pd.Timedelta(days=1)\n",
    "\n",
    "# Create the DataFrame\n",
    "df_subscriptions = pd.DataFrame(subscription_data)\n",
    "df_subscriptions['start_date'] = pd.to_datetime(df_subscriptions['start_date']).dt.date\n",
    "df_subscriptions['end_date'] = pd.to_datetime(df_subscriptions['end_date']).dt.date\n",
    "df_subscriptions['end_date'] = df_subscriptions['end_date'].apply(lambda x: None if pd.isna(x) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39b86a46-affd-43cd-a075-e68c1a3a6010",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" raw_merchant_transaction  \"\"\"\n",
    "\n",
    "# Assuming df_merchants is available from the first step\n",
    "# We only want to generate transactions for 'Active' or 'Suspended' merchants\n",
    "active_merchant_ids = df_merchants[df_merchants['status'].isin(['Active', 'Suspended'])]['merchant_id'].tolist()\n",
    "\n",
    "NUM_TRANSACTIONS = 10000\n",
    "transaction_data = []\n",
    "transaction_id_counter = 1\n",
    "\n",
    "for _ in range(NUM_TRANSACTIONS):\n",
    "    # 1. Generate unique ID\n",
    "    transaction_id = f'TXN_{transaction_id_counter:05d}'\n",
    "    \n",
    "    # 2. Pick a random active merchant\n",
    "    merchant_id = random.choice(active_merchant_ids)\n",
    "    \n",
    "    # 3. Generate a timestamp in the last 3 months (July, Aug, Sep 2025)\n",
    "    # The start date is 2025-07-01 and the end date is 2025-09-30\n",
    "    transaction_timestamp = fake.date_time_between(start_date='-3M', end_date=datetime.now()) \n",
    "    \n",
    "    # 4. Generate a random transaction amount (between $1 and $1000)\n",
    "    gross_amount_usd = round(random.uniform(1.0, 1000.0), 2)\n",
    "    \n",
    "    # 5. Payment method\n",
    "    payment_method = random.choice(['Card', 'UPI', 'Wallet', 'Net Banking'])\n",
    "    \n",
    "    transaction_data.append({\n",
    "        'transaction_id': transaction_id,\n",
    "        'merchant_id': merchant_id,\n",
    "        'transaction_timestamp': transaction_timestamp,\n",
    "        'gross_amount_usd': gross_amount_usd,\n",
    "        'payment_method': payment_method\n",
    "    })\n",
    "    transaction_id_counter += 1\n",
    "\n",
    "# Create the final Bronze DataFrame\n",
    "df_transactions = pd.DataFrame(transaction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1985e46e-09f8-4829-9f10-9cb18c1531ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert df_merchants (Pandas) to spark_df_merchants (PySpark)\n",
    "spark_df_merchants = spark.createDataFrame(df_merchants) # raw_merchant_profiles\n",
    "spark_df_subscriptions = spark.createDataFrame(df_subscriptions) # raw_merchant_subscriptions\n",
    "spark_df_transactions = spark.createDataFrame(df_transactions) # raw_merchant_transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd5761dd-b031-4e53-a5c1-5b0c27898ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " merchants: 100, subscriptions: 212, transactions: 10000 \n"
     ]
    }
   ],
   "source": [
    "print(f\" merchants: {spark_df_merchants.count()}, subscriptions: {spark_df_subscriptions.count()}, transactions: {spark_df_transactions.count()} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1510c1f-2f9e-4573-befc-ecf49c57a2cd",
   "metadata": {},
   "source": [
    "# Silver - Data Vault 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b05f270-0d61-4181-920a-816e086a843e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp, sha2, lit, col\n",
    "\n",
    "HUB_MERCHANT = (\n",
    "    spark_df_merchants \n",
    "    .select(\"merchant_id\")                                      # 1. Select the Business Key\n",
    "    .distinct()                                                 # 2. Only keep unique Business Keys\n",
    "    .withColumnRenamed(\"merchant_id\", \"MERCHANT_BK\")            # 3. Rename BK for clarity\n",
    "    .withColumn(\"HUB_MERCHANT_HK\", sha2(col(\"MERCHANT_BK\"), 256)) # 4. Generate the Hash Key (PK)\n",
    "    .withColumn(\"LOAD_DATETIME\", current_timestamp())          # 5. Generate the Load Timestamp\n",
    "    .withColumn(\"RECORD_SOURCE\", lit(\"raw_merchant_profiles\"))  # 6. Define the Source\n",
    "    .select(\"HUB_MERCHANT_HK\", \"MERCHANT_BK\", \"LOAD_DATETIME\", \"RECORD_SOURCE\") # Final order\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48062a70-3ee7-419f-acb4-6e57d502b431",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUB_TRANSACTION = (\n",
    "    spark_df_transactions\n",
    "    .select(\"transaction_id\")                                       # 1. Select the Business Key\n",
    "    .distinct()                                        # 2. Only keep unique Business Keys\n",
    "    .withColumnRenamed(\"transaction_id\", \"TRANSACTION_BK\")          # 3. Rename BK for clarity\n",
    "    .withColumn(\"HUB_TRANSACTION_HK\", sha2(col(\"TRANSACTION_BK\"), 256)) # 4. Generate the Hash Key (PK)\n",
    "    .withColumn(\"LOAD_DATETIME\", current_timestamp())   # 5. Generate the Load Timestamp\n",
    "    .withColumn(\"RECORD_SOURCE\", lit(\"raw_merchant_transaction\"))             # 6. Define the Source\n",
    "    .select(\"HUB_TRANSACTION_HK\", \"TRANSACTION_BK\", \"LOAD_DATETIME\", \"RECORD_SOURCE\") \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73541026-6ac7-4801-ac2f-77dc9d3bdd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUB_SUBSCRIPTION = (\n",
    "    spark_df_subscriptions\n",
    "    .select(\"subscription_id\")                                       # 1. Select the Business Key\n",
    "    .distinct()                                        # 2. Only keep unique Business Keys\n",
    "    .withColumnRenamed(\"subscription_id\", \"SUBSCRIPTION_BK\")          # 3. Rename BK for clarity\n",
    "    .withColumn(\"HUB_SUBSCRIPTION_HK\", sha2(col(\"SUBSCRIPTION_BK\"), 256)) # 4. Generate the Hash Key (PK)\n",
    "    .withColumn(\"LOAD_DATETIME\", current_timestamp())   # 5. Generate the Load Timestamp\n",
    "    .withColumn(\"RECORD_SOURCE\", lit(\"raw_merchant_subscriptions\"))             # 6. Define the Source\n",
    "    .select(\"HUB_SUBSCRIPTION_HK\", \"SUBSCRIPTION_BK\", \"LOAD_DATETIME\", \"RECORD_SOURCE\") \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8182c556-a7f6-4687-aebb-0d1d9f3fe529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws\n",
    "\n",
    "SAT_MERCHANT_PROFILE = (\n",
    "    spark_df_merchants \n",
    "    .withColumn(\"HUB_MERCHANT_HK\", sha2(col(\"merchant_id\"), 256)) # 1. Create the Hub Hash Key\n",
    "    .withColumn(\"HASH_DIFF\", sha2(concat_ws(\"|\", col(\"merchant_name\"), col(\"status\"), col(\"signup_date\").cast(\"string\") ), 256) )  # 2. Create the Hash Difference (HD)\n",
    "    .withColumn(\"LOAD_DATETIME\", current_timestamp())     # 3. Add Audit Columns\n",
    "    .withColumn(\"RECORD_SOURCE\", lit(\"raw_merchant_profiles\"))\n",
    "    .select(\n",
    "        \"HUB_MERCHANT_HK\",\n",
    "        \"LOAD_DATETIME\",\n",
    "        \"HASH_DIFF\",\n",
    "        \"merchant_name\",\n",
    "        \"status\",\n",
    "        \"signup_date\",\n",
    "        \"RECORD_SOURCE\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40db91ac-7537-44c0-afef-529a19c72f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws\n",
    "SAT_SUBSCRIPTION_DETAILS = (\n",
    "    spark_df_subscriptions \n",
    "    .withColumn(\"HUB_SUBSCRIPTION_HK\", sha2(col(\"subscription_id\"), 256))  # 1. Create the Hub Hash Key (Recalculated for decoupling)\n",
    "    .withColumn(\"HASH_DIFF\", sha2(concat_ws(\"|\", col(\"pricing_tier\"), col(\"fee_percentage\").cast(\"string\"), col(\"start_date\").cast(\"string\"), col(\"end_date\").cast(\"string\") ), 256))  # 2. Create the Hash Difference (HD)\n",
    "    .withColumn(\"LOAD_DATETIME\", current_timestamp())     # 3. Add Audit Columns\n",
    "    .withColumn(\"RECORD_SOURCE\", lit(\"raw_merchant_subscriptions\"))\n",
    "    .select(\n",
    "        \"HUB_SUBSCRIPTION_HK\",\n",
    "        \"LOAD_DATETIME\",\n",
    "        \"HASH_DIFF\",\n",
    "        \"pricing_tier\",\n",
    "        \"fee_percentage\",\n",
    "        \"start_date\",\n",
    "        \"end_date\",\n",
    "        \"RECORD_SOURCE\"\n",
    "    ) # 4. Select the final Satellite columns \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43672474-814c-43c4-85d9-53d5e804ccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp, sha2, lit, col, concat_ws\n",
    "\n",
    "LNK_MERCHANT_SUBSCRIPTION = (\n",
    "    spark_df_subscriptions\n",
    "    .select(\"merchant_id\", \"subscription_id\") \n",
    "    .distinct()  # Links are unique relationships, not unique rows of the source\n",
    "    .withColumn(\"HUB_MERCHANT_HK\", sha2(col(\"merchant_id\"), 256))  # 1. Recalculate the two Hub Hash Keys (Foreign Keys)\n",
    "    .withColumn(\"HUB_SUBSCRIPTION_HK\", sha2(col(\"subscription_id\"), 256)) # 1.2 Recalculate the two Hub Hash Keys (Foreign Keys)\n",
    "    .withColumn(\"LNK_MERCHANT_SUBSCRIPTION_HK\", sha2(concat_ws(\"|\", col(\"HUB_MERCHANT_HK\"), col(\"HUB_SUBSCRIPTION_HK\")), 256))  # 2. Create the Link Hash Key (Primary Key)\n",
    "    .withColumn(\"LOAD_DATETIME\", current_timestamp()) # 3. Add Audit Columns\n",
    "    .withColumn(\"RECORD_SOURCE\", lit(\"raw_merchant_subscriptions\"))\n",
    "    \n",
    "    # 4. Select the final Link columns (LHK, HK1, HK2, Audit)\n",
    "    .select(\n",
    "        \"LNK_MERCHANT_SUBSCRIPTION_HK\",\n",
    "        \"HUB_MERCHANT_HK\",\n",
    "        \"HUB_SUBSCRIPTION_HK\",\n",
    "        \"LOAD_DATETIME\",\n",
    "        \"RECORD_SOURCE\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a93e27-8d66-4705-b5f2-e099e79ec774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp, sha2, lit, col, concat_ws\n",
    "\n",
    "LNK_MERCHANT_SUBSCRIPTION = (\n",
    "    spark_df_transactions\n",
    "    .select(\"merchant_id\", \"subscription_id\") \n",
    "    .distinct()  # Links are unique relationships, not unique rows of the source\n",
    "    .withColumn(\"HUB_MERCHANT_HK\", sha2(col(\"merchant_id\"), 256))  # 1. Recalculate the two Hub Hash Keys (Foreign Keys)\n",
    "    .withColumn(\"HUB_SUBSCRIPTION_HK\", sha2(col(\"subscription_id\"), 256)) # 1.2 Recalculate the two Hub Hash Keys (Foreign Keys)\n",
    "    .withColumn(\"LNK_MERCHANT_SUBSCRIPTION_HK\", sha2(concat_ws(\"|\", col(\"HUB_MERCHANT_HK\"), col(\"HUB_SUBSCRIPTION_HK\")), 256))  # 2. Create the Link Hash Key (Primary Key)\n",
    "    .withColumn(\"LOAD_DATETIME\", current_timestamp()) # 3. Add Audit Columns\n",
    "    .withColumn(\"RECORD_SOURCE\", lit(\"raw_merchant_subscriptions\"))\n",
    "    \n",
    "    # 4. Select the final Link columns (LHK, HK1, HK2, Audit)\n",
    "    .select(\n",
    "        \"LNK_MERCHANT_SUBSCRIPTION_HK\",\n",
    "        \"HUB_MERCHANT_HK\",\n",
    "        \"HUB_SUBSCRIPTION_HK\",\n",
    "        \"LOAD_DATETIME\",\n",
    "        \"RECORD_SOURCE\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6edb0517-f73a-4bc7-90d3-4e9d31c03e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws\n",
    "\n",
    "LNK_MERCHANT_TRANSACTION = (\n",
    "    spark_df_transactions\n",
    "    .select(\"merchant_id\", \"transaction_id\")  # Select the two required Business Keys (IDs) from the raw source\n",
    "    .distinct()  # Not strictly needed for a transaction event, but good practice\n",
    "    .withColumn(\"HUB_MERCHANT_HK\", sha2(col(\"merchant_id\"), 256))  # 1. Recalculate the two Hub Hash Keys (Foreign Keys)\n",
    "    .withColumn(\"HUB_TRANSACTION_HK\", sha2(col(\"transaction_id\"), 256))  # 1.1 Recalculate the two Hub Hash Keys (Foreign Keys)\n",
    "    .withColumn(\"LNK_MERCHANT_TRANSACTION_HK\", sha2(concat_ws(\"|\", col(\"HUB_MERCHANT_HK\"), col(\"HUB_TRANSACTION_HK\")), 256))  # 2. Create the Link Hash Key (LHK) (The Primary Key)\n",
    "    .withColumn(\"LOAD_DATETIME\", current_timestamp())  # 3. Add Audit Columns\n",
    "    .withColumn(\"RECORD_SOURCE\", lit(\"raw_payment_transactions\"))\n",
    "    .select(\n",
    "        \"LNK_MERCHANT_TRANSACTION_HK\",\n",
    "        \"HUB_MERCHANT_HK\",\n",
    "        \"HUB_TRANSACTION_HK\",\n",
    "        \"LOAD_DATETIME\",\n",
    "        \"RECORD_SOURCE\"\n",
    "    )# 4. Select the final Link columns (LHK, HK1, HK2, Audit)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c53c2b-f38b-4ffd-be58-4ae012331399",
   "metadata": {},
   "source": [
    "# Gold Layer - Kimball (Dimensional Data Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f846a507-bb83-4b16-9e95-e14813b5bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_MERCHANT = (\n",
    "    SAT_MERCHANT_PROFILE\n",
    "    .join(\n",
    "        HUB_MERCHANT.select(\"HUB_MERCHANT_HK\", \"MERCHANT_BK\"), \n",
    "        on=[\"HUB_MERCHANT_HK\"], \n",
    "        how=\"inner\"\n",
    "    )\n",
    "    # Select the columns for the final dimension table:\n",
    "    .select(\n",
    "        col(\"HUB_MERCHANT_HK\"),\n",
    "        col(\"MERCHANT_BK\"),\n",
    "        col(\"merchant_name\"),\n",
    "        col(\"status\"),\n",
    "        col(\"signup_date\"),\n",
    "\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48e55705-3ca6-4ef3-8eed-0cadfa272ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "DIM_SUBSCRIPTION = (\n",
    "    SAT_SUBSCRIPTION_DETAILS \n",
    "    .join(\n",
    "        HUB_SUBSCRIPTION.select(\"HUB_SUBSCRIPTION_HK\", \"SUBSCRIPTION_BK\"), \n",
    "        on=[\"HUB_SUBSCRIPTION_HK\"], \n",
    "        how=\"inner\"\n",
    "    )\n",
    "    .select(\n",
    "        col(\"HUB_SUBSCRIPTION_HK\"),\n",
    "        col(\"SUBSCRIPTION_BK\"),\n",
    "        col(\"pricing_tier\"),\n",
    "        col(\"fee_percentage\"),\n",
    "        col(\"start_date\"),\n",
    "        col(\"end_date\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55451c9a-4618-4532-9029-1fcf1166910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp, sha2, lit, col, concat_ws, to_date, when\n",
    "\n",
    "fact_prep = (\n",
    "    spark_df_transactions \n",
    "    # Recalculate the two necessary Hub Hash Keys\n",
    "    .withColumn(\"HUB_MERCHANT_HK\", sha2(col(\"merchant_id\"), 256))\n",
    "    .withColumn(\"HUB_TRANSACTION_HK\", sha2(col(\"transaction_id\"), 256))\n",
    "    .withColumnRenamed(\"transaction_timestamp\", \"TRANSACTION_DATETIME\")\n",
    "    .select(\n",
    "        \"HUB_MERCHANT_HK\", \n",
    "        \"HUB_TRANSACTION_HK\", \n",
    "        \"TRANSACTION_DATETIME\", \n",
    "        \"gross_amount_usd\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c3ec5cb-accf-43e3-ae1b-7c5ca02df74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Link table contains HUB_MERCHANT_HK and HUB_SUBSCRIPTION_HK\n",
    "# We are only selecting the two HKs here, as we don't need the LNK_HK for the Fact table.\n",
    "\n",
    "bridged_fact = (\n",
    "    fact_prep\n",
    "    .join(\n",
    "        LNK_MERCHANT_SUBSCRIPTION.select(\"HUB_MERCHANT_HK\", \"HUB_SUBSCRIPTION_HK\"),\n",
    "        on=[\"HUB_MERCHANT_HK\"],\n",
    "        how=\"inner\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ea688abd-c7b8-47cd-bd30-eb93e0cdd781",
   "metadata": {},
   "outputs": [],
   "source": [
    "FACT_PAYMENT_REVENUE = (\n",
    "bridged_fact.alias(\"bf\")\n",
    "    .join(\n",
    "        SAT_SUBSCRIPTION_DETAILS.alias(\"ssd\"), \n",
    "        on=( \n",
    "            (col(\"ssd.HUB_SUBSCRIPTION_HK\") == col(\"bf.HUB_SUBSCRIPTION_HK\")) \n",
    "            & (col(\"bf.TRANSACTION_DATETIME\") >= to_date(col(\"ssd.start_date\")))\n",
    "            & (col(\"bf.TRANSACTION_DATETIME\") < to_date(when(col(\"ssd.start_date\").isNull(), lit(\"2099-12-31\")).otherwise(col(\"ssd.end_date\"))))\n",
    "        ), how=\"inner\"\n",
    "    )\n",
    "    .withColumn(\"PLATFORM_REVENUE_USD\", round((col(\"bf.gross_amount_usd\") * col(\"ssd.fee_percentage\")) / 100, 2)) \n",
    "    .select(\"bf.HUB_MERCHANT_HK\", \"bf.HUB_TRANSACTION_HK\", \"bf.HUB_SUBSCRIPTION_HK\", \"bf.TRANSACTION_DATETIME\", \"bf.gross_amount_usd\", \"PLATFORM_REVENUE_USD\")\n",
    "    .withColumnRenamed(\"HUB_SUBSCRIPTION_HK\", \"HK_SUBSCRIPTION_FK\")\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cc05af-02ee-4bc5-a1f2-a1878400c656",
   "metadata": {},
   "source": [
    "## Questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9f1abf9e-cada-48b7-913f-7c5804e92997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+------------------+\n",
      "|total_revenue_pro_active|Avg_Fee_Percentage|\n",
      "+------------------------+------------------+\n",
      "|      3280.1600000000003|               1.5|\n",
      "+------------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"1. Find the total platform revenue from Pro plans and the average fee percentage paid by Active merchants \"\"\"\n",
    "\n",
    "FACT_PAYMENT_REVENUE.alias(\"fpr\") \\\n",
    "    .join(DIM_MERCHANT.alias(\"dm\"), on=(col(\"dm.HUB_MERCHANT_HK\")==col(\"fpr.HUB_MERCHANT_HK\")), how= \"inner\") \\\n",
    "    .join(DIM_SUBSCRIPTION.alias('ds'), on=(col(\"ds.HUB_SUBSCRIPTION_HK\")==col(\"fpr.HK_SUBSCRIPTION_FK\")), how=\"inner\") \\\n",
    "    .select(col(\"dm.status\"), col(\"dm.merchant_name\"),col(\"ds.pricing_tier\"),col(\"ds.fee_percentage\"), col(\"fpr.PLATFORM_REVENUE_USD\"), col('fpr.TRANSACTION_DATETIME'))\\\n",
    "    .filter((col('status')=='Active') & (col('pricing_tier')== 'Pro'))\\\n",
    "    .agg(sum(col(\"PLATFORM_REVENUE_USD\")).alias('total_revenue_pro_active'), avg(col(\"fee_percentage\")).alias(\"Avg_Fee_Percentage\")  )\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3a4a64ea-0dcd-4d5f-b08f-037358f09b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+------------------------------+-----------------------------+----------------------+\n",
      "|       merchant_name|pricing_tier|No_of_times_Subscription_taken|Total_Gross_Revenue_Processed|Average_Fee_Percentage|\n",
      "+--------------------+------------+------------------------------+-----------------------------+----------------------+\n",
      "|     Alvarez-Sanchez|  Enterprise|                             7|                      2516.98|                   1.0|\n",
      "|Baird, Wright and...|         Pro|                            74|                     41985.97|                   1.5|\n",
      "|Collins, Levine a...|  Enterprise|                            45|                     19229.86|                   1.0|\n",
      "|       Conway-Martin|     Starter|                            35|                     15611.27|                   2.9|\n",
      "|       Conway-Martin|  Enterprise|                            10|                      4194.37|                   1.0|\n",
      "|Deleon, Reed and ...|     Starter|                            34|                     17423.67|                   2.9|\n",
      "|       Dominguez Inc|         Pro|                             7|                      3939.74|                   1.5|\n",
      "|       Dominguez Inc|  Enterprise|                             2|                      1237.96|                   1.0|\n",
      "|      Evans and Sons|         Pro|                            61|                      32409.6|                   1.5|\n",
      "|      Evans and Sons|     Starter|                             3|                      1237.35|                   2.9|\n",
      "|Garcia, Vasquez a...|  Enterprise|                            63|                     30137.32|                   1.0|\n",
      "|         Gilbert Ltd|  Enterprise|                            46|                      23767.7|                   1.0|\n",
      "|         Hoover-King|  Enterprise|                            86|                     42658.01|                   1.0|\n",
      "|Jackson, Matthews...|         Pro|                            59|                     30523.29|                   1.5|\n",
      "|Jackson, Matthews...|     Starter|                            40|                     20096.05|                   2.9|\n",
      "|        Keller Group|         Pro|                            68|                      33282.4|                   1.5|\n",
      "|        Keller Group|     Starter|                            52|                     26339.79|                   2.9|\n",
      "|      Leonard-Wilcox|         Pro|                            37|                      16923.4|                   1.5|\n",
      "|Lewis, Wheeler an...|         Pro|                            17|                      8914.58|                   1.5|\n",
      "|Lewis, Wheeler an...|  Enterprise|                             1|                       477.18|                   1.0|\n",
      "+--------------------+------------+------------------------------+-----------------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "For every unique Merchant and Subscription Plan Tier combination, what is the total sales volume processed, \n",
    "the effective average fee charged ?\n",
    "\"\"\"\n",
    "\n",
    "merchant_subscription_fee_query = (\n",
    "    FACT_PAYMENT_REVENUE.alias(\"fpr\")\n",
    "    .join(\n",
    "        DIM_MERCHANT.alias(\"dm\"), \n",
    "        on=(col(\"dm.HUB_MERCHANT_HK\") == col(\"fpr.HUB_MERCHANT_HK\")), \n",
    "        how=\"inner\"\n",
    "    )\n",
    "    .join(\n",
    "        DIM_SUBSCRIPTION.alias('ds'), \n",
    "        on=(col(\"ds.HUB_SUBSCRIPTION_HK\") == col(\"fpr.HK_SUBSCRIPTION_FK\")), \n",
    "        how=\"inner\"\n",
    "    )    \n",
    "    .groupBy(\n",
    "        col(\"dm.merchant_name\"), \n",
    "        col(\"ds.pricing_tier\")\n",
    "    )\n",
    "    .agg(\n",
    "        count(col(\"ds.SUBSCRIPTION_BK\")).alias('No_of_times_Subscription_taken'),\n",
    "        round(sum(col(\"fpr.gross_amount_usd\")),2).alias(\"Total_Gross_Revenue_Processed\"),\n",
    "        round(avg(col(\"ds.fee_percentage\")),2).alias(\"Average_Fee_Percentage\")\n",
    "    )\n",
    "    .orderBy(col('dm.merchant_name'), col(\"Total_Gross_Revenue_Processed\").desc())\n",
    ")\n",
    "\n",
    "merchant_subscription_fee_query.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd471a2f-e679-42f2-8884-f226b113e0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
